{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab03.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 3: Exploring Summary Statistics and Loss Functions\n",
    "\n",
    "In this lab, you will:\n",
    "\n",
    "1. Define loss functions and find their minimum values.\n",
    "2. Explore different statistics and techniques for optimization.\n",
    "\n",
    "**This assignment should be completed and submitted before 11:59 PM on Monday Sep 9, 2019.**\n",
    "\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk to others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Loss Functions\n",
    "\n",
    "A loss function is a measure of how well a model is able to predict the expected outcome. In other words, it measures the deviations of the predicted values from the observed values. In this lab we will implement the squared loss and absolute loss functions.  \n",
    "\n",
    "In the formulations below *y* represents the observed values and *c* stands for some constant value representing a summary statistic.\n",
    "\n",
    "1. **Squared Loss** (also known as the $L^2$ loss pronounced \"ell-two\"):\n",
    "\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "L\\left(y, c \\right) = \\left( y - c\\right)^2\n",
    "$$\n",
    "\n",
    "2. **Absolute Loss** (also known as the $L^1$ loss pronounced \"ell-one\"):\n",
    "\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "L\\left(y, c \\right) = \\left| y - c \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "33c63379-d85b-4638-8183-d008fdb96de7",
    "_uuid": "7ad7f9f24df7dba8ac92d234890835f6b9970834",
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "imports1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squared Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 1a: Implement the squared loss function\n",
    "\n",
    "\n",
    "$$\\Large\n",
    "L\\left(y,  c\\right) = \\left( y - c \\right)^2\n",
    "$$\n",
    "\n",
    "Using the comments below, implement the squared loss function. Your answer should not use any loops.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_obs, c):\n",
    "    \"\"\"\n",
    "    Calculate the squared loss of the observed data and a summary statistic.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    y_obs: an observed value\n",
    "    c : some constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    The squared loss between the observation and the summary statistic.\n",
    "    \"\"\"\n",
    "    return (y_obs - c)**2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1b: Plotting the Squared Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let us now consider the case where `y_obs` equals 10. For arbitrary values of `c`, plot the squared loss using the function you implemented in the previous question. Don't forget to label your graph.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = 10\n",
    "c_values = np.linspace(0, 20, 100) # some arbitrary values of c\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "plt.plot(c_values, squared_loss(c_values, y_obs))\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('L2 loss');\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Mean Squared Error for the Tips Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our knowledge to some real world data. Below you are given an array of tips from a restaurant. In this section, you will try to find the best statistic to represent the tips given in the array. The simple procedure you will use in this lab includes constructing the mean squared error (MSE) for the tips data and finding the value that minimizes the MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "loaddata",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell, do not change anything\n",
    "df = sns.load_dataset(\"tips\")\n",
    "tips = np.array(df['tip']) # array of observed tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now, we can extend the above loss functions to an entire dataset by taking the average. Let the dataset $\\mathcal{D}$ be the set of observations:\n",
    "\n",
    "$$\\Large\\mathcal{D} = \\{x_1, \\ldots, x_n\\}$$\n",
    "\n",
    "where $x_i$ is the $i^{th}$ tip.\n",
    "\n",
    "We can define the average loss over the dataset as:\n",
    "\n",
    "$$\\Large\n",
    "L\\left(c, \\mathcal{D}\\right) = \\frac{1}{n} \\sum_{i=1}^n L(x_i, c)\n",
    "$$\n",
    "\n",
    "Define the `mean_squared_error` function which computes the mean squared error given the data and a value for `c`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(c, data):\n",
    "    return np.mean([squared_loss(c, d) for d in data]) # SOLUTION\n",
    "\n",
    "mean_squared_error(5.3, tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below plot the mean squared error for different `c` values. Note that `c_values` are given. Make sure to label the axes on your plot. Remember to use the `tips` variable we defined earlier.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.linspace(0, 6, 100)\n",
    "# BEGIN SOLUTION\n",
    "mse = [mean_squared_error(c, tips) for c in c_values]\n",
    "plt.plot(c_values, mse)\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('L2 loss')\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Find the value of `c` that minimizes the L2 loss above via observation of the plot you've generated. Round your answer to the nearest integer.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_observed_mse = 3 # SOLUTION\n",
    "min_observed_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Find the Minimizing Value for Our Tips Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below plots some arbitrary 4th degree polynomial function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.linspace(-4, 2.5, 100)\n",
    "\n",
    "def fx(x):\n",
    "    return 0.1 * x**4 + 0.2*x**3 + 0.2 * x **2 + 1 * x + 10\n",
    "\n",
    "plt.plot(x_values, fx(x_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the plot, we see that the x which minimizes the function is slightly larger than -2. What if we want the exact value?\n",
    "\n",
    "The function `minimize` from [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) will attempt to minimize any function you throw at it.\n",
    "\n",
    "Try running the cell below, and you will see that minimize seems to get the answer correct.\n",
    "\n",
    "Note: For today, we'll let minimize work as if by magic. We'll discuss how `minimize` works later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "minimize(fx, x0 = 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fun` value is the minimum value of the function. The `x` is the x which minimizes the function. We can index into the object returned by `minimize` to get these values. We have to add the additional `[0]` at the end because the minimizing x is returned as an array. The reason for this is that `minimize` can also minimize multivariable functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minimization_result_for_fx = minimize(fx, x0 = 0)\n",
    "min_of_fx = minimization_result_for_fx['fun']\n",
    "x_which_minimizes_fx = minimization_result_for_fx['x'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `x0` that we passed to the `minimize` function is where the `minimize` function starts looking as it tries to find the minimum. For example, above, `minimize` started its search at x = 1.1 because that's where we told it to start. For the function above, it doesn't really matter what x we start at because the function is nice and has only a single local minimum. More technically, the function is nice because it is [convex](https://en.wikipedia.org/wiki/Convex_function), a property of functions that we will discuss later in the course.\n",
    "\n",
    "`minimize` isn't perfect. For example, if we give it a function with many valleys (also known as local minima) it can get stuck. For example, consider the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_values = np.linspace(-2, 10, 100)\n",
    "\n",
    "def fw(w):\n",
    "    return 0.1 * w**4 - 1.5*w**3 + 6 * w **2 - 1 * w + 10\n",
    "\n",
    "plt.plot(w_values, fw(w_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we start the minimization at w = 6.5, we'll get stuck in the local minimum at w = 7.03. Note that no matter what your actual variable is called in your function, the `minimize` routine still calls the starting point `x0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(fw, x0 = 6.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now using the `minimize function`, find the value of `c` that minimizes the mean squared error for our tips dataset. In other words, you want to find the exact minimum of the plot that you generated in question 2.\n",
    "\n",
    "For autograding purposes, assign `min_scipy` to the value of `c` that minimizes the MSE according to the `minimize` function.\n",
    "\n",
    "Hint: You can't pass your `mean_squared_error` function to `minimize` because `mean_squared_error` has two variables: `c` and `data`. `minimize` will get confused because it thinks it needs to minimize by picking the best `c` and best `data` values. We only want it to play around with `c`.\n",
    "\n",
    "In other words, you need to pass a function of one variable `c` to the `minimize` function, which means you'll need to create a new function of only ONE variable `c`. This is very simple, but also very tricky when you do this for the first time. Make sure to ask for help if you get stuck.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "def mean_squared_error_with_hard_coded_data(c):\n",
    "    return mean_squared_error(c, tips)\n",
    "\n",
    "min_scipy = minimize(mean_squared_error_with_hard_coded_data, x0=0.0)['x'][0]\n",
    "# END SOLUTION\n",
    "# min_scipy = minimize(..., x0=0.0)['x'][0] \n",
    "min_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "From lecture we know that the value of `c` that minimizes the mean squared error is the average of the data. Assign `min_computed` to the mean of the tips dataset, and compare this to the values you observed in questions 2b and 3a.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_computed = np.mean(tips) # SOLUTION\n",
    "min_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflecting on the lab so far, we've now seen 3 ways to find the summary statistic `c` that minimizes the mean squared error:\n",
    "1. Create a plot of the MSE for the given data array vs. `c` and eyeball the minimizing `c`.\n",
    "2. Create a function that returns the MSE for a specific data array as a function of `c` and use the scipy `minimize` function to find the exact `c` which minimizes this function.\n",
    "3. Simply compute the mean of the data array.\n",
    "\n",
    "At this point, you've hopefully convinced yourself that the `mean` is the summary statistic that minimizes mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4: Implement the Absolute Loss \n",
    "\n",
    "In this section, you will follow the exact same steps as above but for the absolute loss function. Absolute loss is defined as:\n",
    "\n",
    "$$\\Large\n",
    "L\\left(y, c\\right) = \\left| y - c\\right|\n",
    "$$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "-->\n",
    "In the cell below define the function `abs_loss` which returns the absolute loss given a value of `c` and `y_obs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_loss(c, y_obs):\n",
    "    return np.abs(c - y_obs) # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4b: Plotting the Absolute Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, plot the absolute loss for different values of `c`. Note that the values of `c` have already been given to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = 10\n",
    "c_values = np.linspace(0, 20, 100) # some arbitrary values of c\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "plt.plot(c_values, abs_loss(c_values, y_obs))\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('L1 loss');\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Mean Absolute Error for the Tips Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define the `mean_absolute_error` function which computes the mean absolute error given the data and a value for `c`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(c, data):\n",
    "    return np.mean([abs_loss(c, d) for d in data]) # SOLUTION\n",
    "\n",
    "mean_absolute_error(5.3, tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below plot the mean absolute error for different `c` values and the `tips` dataset. Note that `c_values` are given. Make sure to label the axes on your plot.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.linspace(0, 6, 100)\n",
    "# BEGIN SOLUTION\n",
    "mae = [mean_absolute_error(c, tips) for c in c_values]\n",
    "plt.plot(c_values, mae)\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('L1 loss');\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the plot looks somewhat to the plot of the mean squared error. Try to identify any key differences you observe and write them down below. This might be more fun with a partner. Note, your answer will not be graded, so don't worry about writing a detailed answer. If you want to see our answer, see the very end of this lab notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the function, let's zoom in closer to the minimizing c. Plot the mean absolute error again using the given `c_values` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.linspace(2.7, 3.02, 100)\n",
    "# BEGIN SOLUTION\n",
    "mae = [mean_absolute_error(c, tips) for c in c_values]\n",
    "plt.plot(c_values, mae);\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "This time, observe that the function is piecewise linear and has a slope of zero near its minimum. Because of the large flat region at the minimum, there are multiple values of `c` that minimize the L1 loss.\n",
    "\n",
    "Give a `c` rounded to the nearest tenth that minimizes L1 loss. By \"rounded to the nearest tenth\" we mean you'd say 7.6 instead of 7.55.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5d\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_observed_mae = 2.9 # SOLUTION\n",
    "min_observed_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Find the Minimizing Value Using Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As before, we will use the `minimize` function to find a solution. Assign `min_abs_scipy` to the value of `c` that minimizes the MAE according to the `minimize` function for the `tips` data. Note: Depending on the `x0` value you specify, you will get different results! \n",
    "\n",
    "Extra: Try various `x0` values and record the different outputs you get from `minimize`. Use the plot you created above to verify that these are all valid minimizing statistics.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "def mean_absolute_error_of_data(c):\n",
    "    return np.mean([abs_loss(c, t) for t in tips])\n",
    "\n",
    "min_abs_scipy = minimize(mean_absolute_error_of_data, x0=0)['x'][0]\n",
    "# END SOLUTION\n",
    "#min_abs_scipy = minimize(..., x0=0.0)['x'][0]\n",
    "min_abs_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q6a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the MSE, there are three ways to compute the summary statistic `c` that minimizes the MAE:\n",
    "1. Create a plot of the MAE for the given data array vs. `c` and eyeball a minimizing `c`.\n",
    "2. Create a function that returns the MAE for a specific data array as a function of `c` and use the scipy `minimize` function to find an exact `c` which minimizes this function.\n",
    "3. Simply compute the ?????? of the data array.\n",
    "\n",
    "Try to figure out what to substitute in for the ?????? above. To this, try out various statistics functions provided by `np`. A list and documentation is available at [https://docs.scipy.org/doc/numpy/reference/routines.statistics.html](https://docs.scipy.org/doc/numpy/reference/routines.statistics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Assign `min_abs_computed` to the correct summary statistic using method `#3` from the previous problem.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_abs_computed = np.median(tips) # SOLUTION\n",
    "min_abs_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q6b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Observations on Differences Between MAE vs. MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in this lab, we said we'd describe our observations about the differences between the MAE and MSE.\n",
    "\n",
    "There are three key differences that we identified between the plots of the MSE and MAE.\n",
    "\n",
    "1. The minimizing c is different (slightly smaller for MAE).\n",
    "2. The plot for MAE increases linearly instead of quadratically as we move far away from the minimizing c.\n",
    "3. The plot for MAE is piecewise linear instead of smooth. Each change in slope happens at the same c value as a data point in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "submit",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: To make sure the test cases run correctly, click `Kernel>Restart & Run All` and make sure all of the test cases are still passing. Doing so will submit your code for you. \n",
    "\n",
    "If your test cases are no longer passing after restarting, you may be missing a variable, or modifications you'd made may not have been recorded (perhaps because you deleted a cell). \n",
    "\n",
    "You may submit this assignment as many times as you'd like before the deadline.\n",
    "\n",
    "**You must restart and run all cells before submitting. Otherwise, you may pass test cases locally, but not on our servers. We will not entertain regrade requests of the form, “my code passed all of my local test cases, but failed the autograder”.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 4 EXPORTED QUESTIONS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('lab03.ipynb', 'lab03.pdf')\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "301px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
